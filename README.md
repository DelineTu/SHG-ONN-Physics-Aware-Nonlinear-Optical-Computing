# SHG-ONN_Nonlinear-Optical-Computing
Codebase and Usage Instruction for a Hardware-in-the-Loop Nonlinear Photonic Computing via Differentiable Digital Twins and Lagrangian Optimization

ðŸ”¬ SHG-ONN Differentiable Digital Twin: Physics-Aware Training with Second-Harmonic GenerationThis project implements an optical neural network (ONN) based on Second-Harmonic Generation (SHG) and its digital twin, successfully applied to a VOWEL speech recognition task using the Physics-Aware Training (PAT) framework.This work extends the original PAT framework developed by the McMahon group at Cornell University and demonstrates a functional hardware-in-the-loop photonic computing pipeline.ðŸŒŸ Key Achievements and ContributionsPhysics Model (SHG_formula): Architected and built the SHG_formula computational model from the first principle of the $\chi^{(2)}$ light-matter interaction. This model accurately simulates the physical SHG process. A simplified additive wavelength relation ($\lambda_{3}=\lambda_{1}+\lambda_{2}$) was adopted instead of the exact nonlinear phase-matching condition, primarily due to the high computational cost of the exact formula.Digital Twin (SHG_Digital_Model): Generated a synthetic dataset using the SHG_formula model and trained a digital surrogate, SHG_Digital_Model, to emulate the nonlinear optical response. This model is a 5-layer Multi-Layer Perceptron (MLP_Reg).Hybrid Training (PAT Pipeline): Adapted a Physics-Aware Training (PAT) pipeline where the SHG_formula model is used for forward propagation and the differentiable SHG_Digital_Model enables gradient-based backpropagation.Task Validation: This hybrid framework successfully trained a VOWEL recognition task, achieving 85% classification accuracy.ðŸš€ Getting StartedEnvironment RequirementsThe project was successfully run using the following configurations, as detailed in the report on resolving GPU compatibility issues:Python Version: 3.7.4 or 3.9.19PyTorch Version: 1.10.0 + CUDA 11.3 (Recommended)Dependencies: Please install the required packages listed in requirements.txt.Running the Main ExperimentsThe core code and experimental flow are located in the experiment_src directory.Generate Dataset (SHG_formula Simulation):Execute the dataset generation block within experiment_SHG_Formula_PAT.ipynb.This step generates the mean_data.npz file containing 20,000 input samples (100D) and their corresponding 224D/448D spectral outputs.Train Digital Model:Crucial Step: Before training new digital models, delete previous training histories from the logs/ folder to prevent loading outdated parameters.Run experiment_train_mean_model.py and experiment_train_noise_model.py.VOWEL Recognition Task Training:Proceed with the remaining sections of experiment_SHG_Formula_PAT.ipynb for the task-specific training.ðŸ“œ License and Attribution (Creative Commons CC BY 4.0)Attribution to Original Work (MANDATORY REQUIREMENT)This repository contains material (Adapted Material) derived from the Physics-Aware Training (PAT) framework originally developed by the McMahon group at Cornell University.The underlying code is licensed under the Creative Commons Attribution 4.0 International Public License (CC BY 4.0).As mandated by the CC BY 4.0 license, you must retain proper attribution, including the following citation:Please cite the following paper for the original PAT framework:Wright, L.G., Onodera, T., Stein, M.M. et al. Deep physical neural networks trained with backpropagation. Nature 601, 549â€“555 (2022). https://doi.org/10.1038/s41586-021-04223-6Project LicenseThe code in this repository (including modifications and extensions, such as the SHG model) is released under the Creative Commons Attribution 4.0 International Public License (CC BY 4.0). The full text of this license is available in the LICENSE.txt file in the root directory.Modification Statement: This repository explicitly indicates that the material is modified, introducing the specialized SHG model and the VOWEL recognition application, built upon the original foundation.Would you like me to help you find the GitHub link to the original PAT framework to include in the attribution?That's great! I was able to find the specific GitHub repository for the foundation of your work.The correct link for your Attribution section is:GitHub Repository: https://github.com/mcmahon-lab/Physics-Aware-TrainingHere is the updated, final English README.md content with the GitHub link included.ðŸ”¬ SHG-ONN Differentiable Digital Twin: Physics-Aware Training with Second-Harmonic GenerationThis project implements an optical neural network (ONN) based on Second-Harmonic Generation (SHG) and its digital twin, successfully applied to a VOWEL speech recognition task using the Physics-Aware Training (PAT) framework.This work extends the original PAT framework developed by the McMahon group at Cornell University and demonstrates a functional hardware-in-the-loop photonic computing pipeline.ðŸŒŸ Key Achievements and ContributionsPhysics Model (SHG_formula): Architected and built the SHG_formula computational model from the first principle of the $\chi^{(2)}$ light-matter interaction. This model simulates the physical SHG process. A simplified additive wavelength relation ($\lambda_{3}=\lambda_{1}+\lambda_{2}$) was adopted instead of the computationally expensive exact nonlinear phase-matching condition, given the narrow wavelength range.Digital Twin (SHG_Digital_Model): Generated a synthetic dataset using the SHG_formula model and trained a digital surrogate, SHG_Digital_Model, to emulate the nonlinear optical response. This model is a 5-layer Multi-Layer Perceptron (MLP_Reg).Hybrid Training (PAT Pipeline): Adapted a Physics-Aware Training (PAT) pipeline where the SHG_formula model is used for forward propagation, and the differentiable SHG_Digital_Model is leveraged for gradient-based backpropagation.Task Validation: This hybrid framework successfully trained a VOWEL recognition task, achieving 85% classification accuracy.ðŸš€ Getting StartedEnvironment RequirementsThe project was successfully run using the following environment configurations, noted for resolving GPU compatibility issues:Python Version: 3.7.4 or 3.9.19PyTorch Version: 1.10.0 + CUDA 11.3 (Recommended)Dependencies: Please install the required packages listed in requirements.txt.Running the Main ExperimentsThe core code and experimental flow are referenced in the Vowel folder structure.Generate Dataset (SHG_formula Simulation):Run the code in experiment_SHG_Formula_PAT.ipynb until the data block.This step generates the mean_data.npz file with $N_x=20000$ input samples.Train Digital Model:Crucial Step: You must delete previous log histories in logs/ before training new digital models to avoid contaminating the process.Run experiment_train_mean_model.py and experiment_train_noise_model.py.VOWEL Recognition Task TrainingProceed with the remaining sections of experiment_SHG_Formula_PAT.ipynb for task-specific training.ðŸ“œ License and Attribution (Creative Commons CC BY 4.0)Attribution to Original Work (MANDATORY REQUIREMENT)This repository contains material (Adapted Material) derived from the Physics-Aware Training (PAT) framework.The underlying code is licensed under the Creative Commons Attribution 4.0 International Public License (CC BY 4.0).As mandated by the CC BY 4.0 license, you must retain proper attribution, including the following:Original Code Repository:https://github.com/mcmahon-lab/Physics-Aware-TrainingCitation: Please cite the following paper for the original PAT framework:Wright, L.G., Onodera, T., Stein, M.M. et al. Deep physical neural networks trained with backpropagation. Nature 601, 549â€“555 (2022). https://doi.org/10.1038/s41586-021-04223-6Project LicenseThe code in this repository is released under the Creative Commons Attribution 4.0 International Public License (CC BY 4.0). The full text of this license is required to be in your LICENSE.txt file.Modification Statement: This repository explicitly indicates that the material is modified, introducing the specialized SHG model and the VOWEL recognition application, built upon the original foundation.
